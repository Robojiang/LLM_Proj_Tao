#!/bin/bash

# é‡åˆ°é”™è¯¯ç«‹å³åœæ­¢
set -e

# è®¾ç½® GPU
export CUDA_VISIBLE_DEVICES=0

cd /mnt/afs/250010074/llm/LLM_Proj_Tao

# source conda.sh è®© conda activate èƒ½ç”¨
source /opt/miniconda3/etc/profile.d/conda.sh

conda activate llm

echo "ğŸš€ å¼€å§‹è¯„ä¼°å‰©ä½™çš„ Transformer æ¨¡å‹..."

# ============================================================
# Transformer å®éªŒè¯„ä¼° (è¡¥å……éƒ¨åˆ†)
# ============================================================

# 1. Transformer Big (d=768, L=6)
# å¯¹åº” run_tra_exp.sh ä¸­çš„ Group 4 Big Model
echo ">>> Evaluating Transformer Big (d=768, L=6)"
# æ³¨æ„ï¼šè¿™é‡Œå‡è®¾è¯¥å®éªŒå·²ç»è·‘å®Œå¹¶ç”Ÿæˆäº†å¯¹åº”çš„ç›®å½•ï¼Œä½ éœ€è¦æ ¹æ®å®é™…ç”Ÿæˆçš„ç›®å½•åä¿®æ”¹ä¸‹é¢çš„è·¯å¾„
# ç›®å‰æ ¹æ®ä½ çš„ runs ç›®å½•åˆ—è¡¨ï¼Œæœ€æ–°çš„ä¸€ä¸ªæ˜¯ 20251225_124943_transformer_relative_rmsnorm_128_0.0001_768
python eval.py \
    --ckpt ./runs/20251225_124943_transformer_relative_rmsnorm_128_0.0001_768/best.pt \
    --data_dir ./processed_data \
    --test_file test.jsonl \
    --decode beam \
    --beam_size 5 \
    --max_len 50

echo "ğŸ‰ å‰©ä½™ Transformer è¯„ä¼°å®Œæˆï¼"
