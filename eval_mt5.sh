#!/bin/bash

# é‡åˆ°é”™è¯¯ç«‹å³åœæ­¢
set -e

# è®¾ç½® GPU
export CUDA_VISIBLE_DEVICES=0
# è§£å†³ numexpr è­¦å‘Šï¼Œå…è®¸ä½¿ç”¨æ›´å¤š CPU æ ¸å¿ƒè¿›è¡Œè®¡ç®—
export NUMEXPR_MAX_THREADS=192

cd /mnt/afs/250010074/llm/LLM_Proj_Tao

# source conda.sh è®© conda activate èƒ½ç”¨
source /opt/miniconda3/etc/profile.d/conda.sh

conda activate llm

echo "ğŸš€ å¼€å§‹è¯„ä¼° mT5 æ¨¡å‹..."

# ============================================================
# mT5 å®éªŒè¯„ä¼°
# ============================================================

# 1. mT5 LoRA (Raw Data) - 20251225_003937
echo ">>> Evaluating mT5 LoRA (Raw Data) - Run 1"
python eval_t5_raw.py \
    --model_path ./runs/20251225_003937_mt5-finetune-raw_google-mt5-small_lora_raw/best_model \
    --data_dir ./data \
    --test_file test.jsonl \
    --num_beams 4 \
    --max_len 80

# 2. mT5 LoRA (Raw Data) - 20251225_035345
echo ">>> Evaluating mT5 LoRA (Raw Data) - Run 2"
python eval_t5_raw.py \
    --model_path ./runs/20251225_035345_mt5-finetune-raw_google-mt5-small_lora_raw/best_model \
    --data_dir ./data \
    --test_file test.jsonl \
    --num_beams 4 \
    --max_len 80

# 3. mT5 LoRA (Raw Data) - 20251225_070549
echo ">>> Evaluating mT5 LoRA (Raw Data) - Run 3"
python eval_t5_raw.py \
    --model_path ./runs/20251225_070549_mt5-finetune-raw_google-mt5-small_lora_raw/best_model \
    --data_dir ./data \
    --test_file test.jsonl \
    --num_beams 4 \
    --max_len 80

echo "ğŸ‰ æ‰€æœ‰ mT5 è¯„ä¼°å®Œæˆï¼"
