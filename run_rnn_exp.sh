#!/bin/bash

# è®¾ç½®é‡åˆ°é”™è¯¯å³åœæ­¢ï¼Œé˜²æ­¢ä¸€ä¸ªæŒ‚äº†åé¢æ¥ç€è·‘æµªè´¹æ—¶é—´
set -e

cd /mnt/afs/250010074/llm/LLM_Proj_Tao

# source conda.sh è®© conda activate èƒ½ç”¨
source /opt/miniconda3/etc/profile.d/conda.sh

conda activate llm

# æŒ‡å®šä½¿ç”¨çš„ GPUï¼Œä¾‹å¦‚ä½¿ç”¨ 0 å·å¡
export CUDA_VISIBLE_DEVICES=0

echo "ğŸš€ å¼€å§‹è¿è¡Œè‡ªåŠ¨åŒ–å®éªŒè„šæœ¬..."

# ====================================================
# ç¬¬ä¸€ç»„ï¼šRNN åŸºçº¿ä¸æ³¨æ„åŠ›æœºåˆ¶å¯¹æ¯” (RNN Attention Ablation)
# ç›®çš„ï¼šå¯¹æ¯” Dot, General (Multiplicative), Additive çš„æ•ˆæœ
# ====================================================

echo "Running RNN Experiment 1: Dot Product Attention"
python train.py \
    model=rnn \
    model.attn=dot 

echo "Running RNN Experiment 2: General (Multiplicative) Attention"
python train.py \
    model=rnn \
    model.attn=general \

echo "Running RNN Experiment 3: Additive Attention (Expected Best)"
python train.py \
    model=rnn \
    model.attn=additive \

# ====================================================
# ç¬¬äºŒç»„ï¼šRNN è®­ç»ƒç­–ç•¥å¯¹æ¯” (Teacher Forcing)
# ç›®çš„ï¼šå¯¹æ¯” Teacher Forcing = 1.0 (é»˜è®¤) vs 0.8 (Scheduled Sampling)
# æ³¨æ„ï¼šä¸Šé¢çš„ RNN Exp 3 å…¶å®å°±æ˜¯ TF=1.0 çš„å¯¹ç…§ç»„
# ====================================================

echo "Running RNN Experiment 4: Additive Attention with Scheduled Sampling (TF=0.5)"
python train.py \
    model=rnn \
    model.attn=additive \
    model.teacher_forcing=0.5 \

echo "Running RNN Experiment 4: Additive Attention with Scheduled Sampling (TF=0.0)"
python train.py \
    model=rnn \
    model.attn=additive \
    model.teacher_forcing=0 \

echo "ğŸ‰ æ‰€æœ‰å®éªŒè¿è¡Œå®Œæ¯•ï¼è¯·å» WandB æŸ¥çœ‹æ›²çº¿ï¼Œå¹¶è¿è¡Œ eval.py ç”Ÿæˆæœ€ç»ˆ BLEU åˆ†æ•°ã€‚"